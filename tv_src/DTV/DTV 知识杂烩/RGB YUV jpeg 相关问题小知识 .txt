1.什么是RGB？
RGB是红绿蓝三原色的意思，R=Red、G=Green、B=Blue。

2.什么是YUV/YCbCr/YPbPr？
亮 度信号经常被称作Y，色度信号是由两个互相独立的信号组成。视颜色系统和格式不同，两种色度信号经常被称作U和V或Pb和Pr或Cb和Cr。这些都是由不 同的编码格式所产生的，但是实际上，他们的概念基本相同。在DVD中，色度信号被存储成Cb和Cr（C代表颜色，b代表蓝色，r代表红色）。

3.什么是4:4:4、4:2:2、4:2:0？
在 最近十年中，视频工程师发现人眼对色度的敏感程度要低于对亮度的敏感程度。在生理学中，有一条规律，那就是人类视网膜上的视网膜杆细胞要多于视网膜锥细 胞，说得通俗一些，视网膜杆细胞的作用就是识别亮度，而视网膜锥细胞的作用就是识别色度。所以，你的眼睛对于亮和暗的分辨要比对颜色的分辨精细一些。正是 因为这个，在我们的视频存储中，没有必要存储全部颜色信号。既然眼睛看不见，那为什么要浪费存储空间（或者说是金钱）来存储它们呢？
像Beta或VHS之类的消费用录像带就得益于将录像带上的更多带宽留给黑―白信号（被称作“亮度”），将稍少的带宽留给彩色信号（被称作“色度”）。
在MPEG2（也就是DVD使用的压缩格式）当中，Y、Cb、Cr信号是分开储存的（这就是为什么分量视频传输需要三条电缆）。其中Y信号是黑白信号，是以全分辨率存储的。但是，由于人眼对于彩色信息的敏感度较低，色度信号并不是用全分辨率存储的。
色 度信号分辨率最高的格式是4:4:4，也就是说，每4点Y采样，就有相对应的4点Cb和4点Cr。换句话说，在这种格式中，色度信号的分辨率和亮度信号的 分辨率是相同的。这种格式主要应用在视频处理设备内部，避免画面质量在处理过程中降低。当图像被存储到Master Tape，比如D1或者D5，的时候，颜色信号通常被削减为4:2:2。


在图中，你可以看到4:4:4格式的亮度、色度采样分布。就像图中所表示的，画面中每个象素都有与之对应的色度和亮度采样信息。[/center]
其 次就是4:2:2，就是说，每4点Y采样，就有2点Cb和2点Cr。在这种格式中，色度信号的扫描线数量和亮度信号一样多，但是每条扫描线上的色度采样点 数却只有亮度信号的一半。当4:2:2信号被解码的时候，“缺失”的色度采样，通常由一定的内插补点算法通过它两侧的色度信息运算补充。

看4:2:2格式亮度、色度采样的分布情况。在这里，每个象素都有与之对应的亮度采样，同时一半的色度采样被丢弃，所以我们看到，色度采样信号每隔 一个采样点才有一个。当着张画面显示的时候，缺少的色度信息会由两侧的颜色通过内插补点的方式运算得到。就像上面提到的那样，人眼对色度的敏感程度不如亮 度，大多数人并不能分辨出4:2:2和4:4:4颜色构成的画面之间的不同。
色度信号分辨率最低的格式，也就是DVD所使用的 格式，就是4:2:0了。事实上4:2:0是一个混乱的称呼，按照字面上理解，4:2:0应该是每4点Y采样，就有2点Cb和0点Cr，但事实上完全不是 这样。事实上，4:2:0的意思是，色度采样在每条横向扫描线上只有亮度采样的一半，扫描线的条数上，也只有亮度的一半！换句话说，无论是横向还是纵向， 色度信号的分辨率都只有亮度信号的一半。举个例子，如果整张画面的尺寸是720*480，那么亮度信号是720*480，色度信号只有360*240。在 4:2:0中，“缺失”的色度采样不单单要由左右相邻的采样通过内插补点计算补充，整行的色度采样也要通过它上下两行的色度采样通过内插补点运算获得。这 样做的原因是为了最经济有效地利用DVD的存储空间。诚然，4:4:4的效果很棒，但是如果要用4:4:4存储一部电影，我们的DVD盘的直径至少要有两 英尺（六十多厘米）！
上图表示了概念上4:2:0颜色格式非交错画面中亮度、色度采样信号的排列情况。同4:2:2格式 一样，每条扫描线中，只有一半的色度采样信息。与4:2:2不同的是，不光是横向的色度信息被“扔掉”了一半，纵向的色度信息也被“扔掉”了一半，整个屏 幕中色度采样只有亮度采样的四分之一。请注意，在4:2:0颜色格式中，色度采样被放在了两条扫描线中间。为什么会这样呢？很简单：DVD盘上的颜色采样 是由其上下两条扫描线的颜色信息“平均”而来的。比如，图三中，第一行颜色采样（Line 1和Line 2中间夹着的那行）是由Line 1和Line 2“平均”得到的，第二行颜色采样（Line 3和Line 4中间夹着的那行）也是同样的道理，是由Line 3和Line 4得到的。
虽然文章中多次提到“平均”这个概念，但是这个“平均”可不是我们通常意义上的(a+B)/2的平均。颜色的处理有极其复杂的算法保证其最大限度地减少失真，接近原始质量。[/center]

4.什么是YV12，什么是YUY2？
YUV格式通常有两大类：打包（packed）格式和平面（planar）格式。前者将YUV分量存放在同一个数组中，通常是几个相邻的像素组成一个宏像素（macro-pixel）；而后者使用三个数组分开存放YUV三个分量，就像是一个三维平面一样。表2.3中的YUY2到Y211都是打包格式，而IF09到YVU9都是平面格式。（注意：在介绍各种具体格式时，YUV各分量都会带有下标，如Y0、U0、V0表示第一个像素的YUV分量，Y1、U1、V1表示第二个像素的YUV分量，以此类推。）

¨ YUY2（和YUYV）格式为每个像素保留Y分量，而UV分量在水平方向上每两个像素采样一次。一个宏像素为4个字节，实际表示2个像素。（4:2:2的意思为一个宏像素中有4个Y分量、2个U分量和2个V分量。）图像数据中YUV分量排列顺序如下：
Y0 U0 Y1 V0    Y2 U2 Y3 V2 …

¨ YVYU格式跟YUY2类似，只是图像数据中YUV分量的排列顺序有所不同：
Y0 V0 Y1 U0    Y2 V2 Y3 U2 …

¨ UYVY格式跟YUY2类似，只是图像数据中YUV分量的排列顺序有所不同：
U0 Y0 V0 Y1    U2 Y2 V2 Y3 …

¨ AYUV格式带有一个Alpha通道，并且为每个像素都提取YUV分量，图像数据格式如下：
A0 Y0 U0 V0    A1 Y1 U1 V1 …

¨ Y41P（和Y411）格式为每个像素保留Y分量，而UV分量在水平方向上每4个像素采样一次。一个宏像素为12个字节，实际表示8个像素。图像数据中YUV分量排列顺序如下：
U0 Y0 V0 Y1    U4 Y2 V4 Y3    Y4 Y5 Y6 Y8 … 

¨ Y211格式在水平方向上Y分量每2个像素采样一次，而UV分量每4个像素采样一次。一个宏像素为4个字节，实际表示4个像素。图像数据中YUV分量排列顺序如下：
Y0 U0 Y2 V0    Y4 U4 Y6 V4 …

¨ YVU9格式为每个像素都提取Y分量，而在UV分量的提取时，首先将图像分成若干个4 x 4的宏块，然后每个宏块提取一个U分量和一个V分量。图像数据存储时，首先是整幅图像的Y分量数组，然后就跟着U分量数组，以及V分量数组。IF09格式与YVU9类似。

¨ IYUV格式为每个像素都提取Y分量，而在UV分量的提取时，首先将图像分成若干个2 x 2的宏块，然后每个宏块提取一个U分量和一个V分量。YV12格式与IYUV类似。

¨ YUV411、YUV420格式多见于DV数据中，前者用于NTSC制，后者用于PAL制。YUV411为每个像素都提取Y分量，而UV分量在水平方向上每4个像素采样一次。YUV420并非V分量采样为0，而是跟YUV411相比，在水平方向上提高一倍色差采样频率，在垂直方向上以U/V间隔的方式减小一半色差采样

5.为什么影片在VDM处理的过程中要选Fast recompress？
选择Fast recompress的原因，现得从Avisynth 2.5讲起。
Avisynth 2.5最大的特色，就是支持YV12直接处理。我们知道原始MPEG数据是YUV4:2:0，也就是YV12的格式，以前我们在做DivX/XviD压缩的时候，处理流程是：
DVD/VCD(YUV 4:2:0) -> DVD2AVI(YUV 4:2:0 ->YUV4:2:2 ->YUV4:4:4 -> RGB24) -> VFAPI(RGB24) -> TMPGEnc/AviUtl/VirtualDub(RGB24) -> DivX/XviD Codec(RGB24 ->YUV4:2:0) -> MPEG-4(YUV 4:2:0)
ps. VFAPI 内部只能以 RGB24 传递数据，所以会转成 RGB24 输出
或是
DVD/VCD(YUV 4:2:0) -> MPG2DEC.DLL(YUV 4:2:0 ->YUV4:2:2) -> Avisynth 2.0.x(只能用支援YUV4:2:2 的滤镜，不能用 RGB24/32 的 filter) -> VirtualDub(YUV 4:2:2，不能使用 VD 的 filter，因为 VD 的 filetr 都是在 RGB32 上处理，压缩时要选 Fast recompress，才会直接原封不动的送YUV4:2:2，也就是 YUY2 的数据给 Codec 压缩) -> DivX/XviD Codec(YUV 4:2:2 ->YUV4:2:0) -> MPEG-4(YUV 4:2:0)
所以以前的处理流程中间要经过好几次YUV<-> RGB 的转换。这个转换是有损的，做得越多次，原始的色彩信息就损失的越严重。而且这个转换的计算又耗时（这就可以解释为什么我们将YV12转为RGB输出时会卡的多，不过，RGB的品质真的更高的多:smile:）。那么有人（Marc FD）就想到，反正最后转成 MPEG 都要存成YUV4:2:0 的格式，那么为什么不干脆一路到底，全程都以YV12处理，也就是所有的 filter 都改写成YV12的版本，直接在YV12上做调整色彩、滤噪讯、IVTC 等工作，这样：
1. 处理的数据量少。（YV12的资料，UV 比YUY2少一半，比RGB 24/32少更多）
2. 不用转换计算
所以速度快。再加上又可以避免YUV<-> RGB 转换的损失，岂不是一举两得？
所以支持YV12的 Avisynth 2.5 就诞生了。
但 是目前VirtualDub还是不支持 YV12，即使选 Fast recompress，VD还是会将YV12的输入转为 YUY2。所以要得到全程YV12处理的好处，必须使用VirtualDubMod才行，这个改版才有支持YV12。只有在选择Fast recompress的时候，VDM才不会进行任何处理，直接将数据丢给编码器压缩，这样就能保留YV12，实现了全程YV12。
 
 
关于 RGB 跟 YUV 的转换：
计 算机彩色显示器显示色彩的原理与彩色电视机一样，都是采用R（Red）、G（Green）、B（Blue）相加混色的原理：通过发射出三种不同强度的电子 束，使屏幕内侧覆盖的红、绿、蓝磷光材料发光而产生色彩。这种色彩的表示方法称为RGB色彩空间表示（它也是多媒体计算机技术中用得最多的一种色彩空间表 示方法）。
根据三基色原理，任意一种色光F都可以用不同分量的R、G、B三色相加混合而成。

F = r [ R ] + g [ G ] + b [ B ]

其中，r、g、b分别为三基色参与混合的系数。当三基色分量都为0（最弱）时混合为黑色光；而当三基色分量都为k（最强）时混合为白色光。调整r、g、b三个系数的值，可以混合出介于黑色光和白色光之间的各种各样的色光。
那 么YUV又从何而来呢？在现代彩色电视系统中，通常采用三管彩色摄像机或彩色CCD摄像机进行摄像，然后把摄得的彩色图像信号经分色、分别放大校正后得到 RGB，再经过矩阵变换电路得到亮度信号Y和两个色差信号R－Y（即U）、B－Y（即V），最后发送端将亮度和色差三个信号分别进行编码，用同一信道发送 出去。这种色彩的表示方法就是所谓的YUV色彩空间表示。
采用YUV色彩空间的重要性是它的亮度信号Y和色度信号U、V是分离的。如果只有Y信号分量而没有U、V分量，那么这样表示的图像就是黑白灰度图像。彩色电视采用YUV空间正是为了用亮度信号Y解决彩色电视机与黑白电视机的兼容问题，使黑白电视机也能接收彩色电视信号。
YUV与RGB相互转换的公式如下（RGB取值范围均为0-255）：

Y = 0.299R + 0.587G + 0.114B
U = -0.147R - 0.289G + 0.436B
V = 0.615R - 0.515G - 0.100B

R = Y + 1.14V
G = Y - 0.39U - 0.58V
B = Y + 2.03U

在DirectShow 中，常见的RGB格式有RGB1、RGB4、RGB8、RGB565、RGB555、RGB24、RGB32、ARGB32等；常见的YUV格式有 YUY2、YUYV、YVYU、UYVY、AYUV、Y41P、Y411、Y211、IF09、IYUV、YV12、YVU9、YUV411、 YUV420等。作为视频媒体类型的辅助说明类型（Subtype），它们对应的GUID见表2.3。

表2.3 常见的RGB和YUV格式

GUID 格式描述
MEDIASUBTYPE_RGB1 2色，每个像素用1位表示，需要调色板
MEDIASUBTYPE_RGB4 16色，每个像素用4位表示，需要调色板
MEDIASUBTYPE_RGB8 256色，每个像素用8位表示，需要调色板
MEDIASUBTYPE_RGB565 每个像素用16位表示，RGB分量分别使用5位、6位、5位
MEDIASUBTYPE_RGB555 每个像素用16位表示，RGB分量都使用5位（剩下的1位不用）
MEDIASUBTYPE_RGB24 每个像素用24位表示，RGB分量各使用8位
MEDIASUBTYPE_RGB32 每个像素用32位表示，RGB分量各使用8位（剩下的8位不用）
MEDIASUBTYPE_ARGB32 每个像素用32位表示，RGB分量各使用8位（剩下的8位用于表示Alpha通道值）
MEDIASUBTYPE_YUY2 YUY2格式，以4:2:2方式打包
MEDIASUBTYPE_YUYV YUYV格式（实际格式与YUY2相同）
MEDIASUBTYPE_YVYU YVYU格式，以4:2:2方式打包
MEDIASUBTYPE_UYVY UYVY格式，以4:2:2方式打包
MEDIASUBTYPE_AYUV 带Alpha通道的4:4:4 YUV格式
MEDIASUBTYPE_Y41P Y41P格式，以4:1:1方式打包
MEDIASUBTYPE_Y411 Y411格式（实际格式与Y41P相同）
MEDIASUBTYPE_Y211 Y211格式
MEDIASUBTYPE_IF09 IF09格式
MEDIASUBTYPE_IYUV IYUV格式
MEDIASUBTYPE_YV12 YV12格式
MEDIASUBTYPE_YVU9 YVU9格式

下面分别介绍各种RGB格式。

¨ RGB1、RGB4、RGB8都是调色板类型的RGB格式，在描述这些媒体类型的格式细节时，通常会在BITMAPINFOHEADER数据结构后面跟着 一个调色板（定义一系列颜色）。它们的图像数据并不是真正的颜色值，而是当前像素颜色值在调色板中的索引。以RGB1（2色位图）为例，比如它的调色板中 定义的两种颜色值依次为0x000000（黑色）和0xFFFFFF（白色），那么图像数据001101010111…（每个像素用1位表示）表示对应各 像素的颜色为：黑黑白白黑白黑白黑白白白…。

¨ RGB565使用16位表示一个像素，这16位中的5位用于R，6位用于G，5位用于B。程序中通常使用一个字（WORD，一个字等于两个字节）来操作一个像素。当读出一个像素后，这个字的各个位意义如下：
高字节 低字节
R R R R R G G G G G G B B B B B
可以组合使用屏蔽字和移位操作来得到RGB各分量的值：

#define RGB565_MASK_RED 0xF800
#define RGB565_MASK_GREEN 0x07E0
#define RGB565_MASK_BLUE 0x001F
R = (wPixel & RGB565_MASK_RED) >> 11; // 取值范围0-31
G = (wPixel & RGB565_MASK_GREEN) >> 5; // 取值范围0-63
B = wPixel & RGB565_MASK_BLUE; // 取值范围0-31

¨ RGB555是另一种16位的RGB格式，RGB分量都用5位表示（剩下的1位不用）。使用一个字读出一个像素后，这个字的各个位意义如下：
高字节 低字节
X R R R R G G G G G B B B B B （X表示不用，可以忽略）
可以组合使用屏蔽字和移位操作来得到RGB各分量的值：

#define RGB555_MASK_RED 0x7C00
#define RGB555_MASK_GREEN 0x03E0
#define RGB555_MASK_BLUE 0x001F
R = (wPixel & RGB555_MASK_RED) >> 10; // 取值范围0-31
G = (wPixel & RGB555_MASK_GREEN) >> 5; // 取值范围0-31
B = wPixel & RGB555_MASK_BLUE; // 取值范围0-31

¨ RGB24使用24位来表示一个像素，RGB分量都用8位表示，取值范围为0-255。注意在内存中RGB各分量的排列顺序为：BGR BGR BGR…。通常可以使用RGBTRIPLE数据结构来操作一个像素，它的定义为：

typedef struct tagRGBTRIPLE { 
BYTE rgbtBlue; // 蓝色分量
BYTE rgbtGreen; // 绿色分量
BYTE rgbtRed; // 红色分量
} RGBTRIPLE;

¨ RGB32使用32位来表示一个像素，RGB分量各用去8位，剩下的8位用作Alpha通道或者不用。（ARGB32就是带Alpha通道的 RGB32。）注意在内存中RGB各分量的排列顺序为：BGRA BGRA BGRA…。通常可以使用RGBQUAD数据结构来操作一个像素，它的定义为：

typedef struct tagRGBQUAD {
BYTE rgbBlue; // 蓝色分量
BYTE rgbGreen; // 绿色分量
BYTE rgbRed; // 红色分量
BYTE rgbReserved; // 保留字节（用作Alpha通道或忽略）
} RGBQUAD;
 
PS:贴上两个网上找到的sourcecode：
 
RGB->YUV
 
Y = 0.299R + 0.587G + 0.114B
Cb = 0.564(B &#8722; Y ) 
Cr = 0.713(R &#8722; Y )

代码：

uint8_t COL_RgbToYuv(uint8_t R,uint8_t G,uint8_t B, uint8_t *y,int8_t *u,int8_t *v)
{
    float rr=R,bb=B,gg=G;
    float yy,uu,vv;

    yy=0.299*rr+ 0.587*gg+ 0.114*bb;
    uu=-0.169*rr+ -0.331*gg+ 0.5*bb;
    vv=0.5*rr+ -0.419*gg+ -0.081*bb;


    if(uu>127) uu=127;
    if(uu<-127) uu=-127;
    *u=(int8_t)floor(uu);

    if(vv>127) vv=127;
    if(vv<-127) vv=-127;
    *v=(int8_t)floor(vv);

    if(yy>255) yy=255;
    if(yy<0) yy=0;
    *y=(uint8_t)floor(yy);

    return 1;
}

YUV->RGB
 
 
 
R = Y + 1.402Cr
G = Y &#8722; 0.344Cb &#8722; 0.714Cr 
B = Y + 1.772Cb

代码：

uint8_t COL_YuvToRgb( uint8_t y,int8_t u,int8_t v,uint8_t *r,uint8_t *g,uint8_t *b)
{
    float rr,bb,gg;
    float yy=y,uu=u,vv=v;

    rr= yy+ 1.402*vv;
    gg= yy+ -0.344*uu+ -0.714*vv;
    bb= yy+ 1.772*uu ;

    #define CLIP(x) if(x>255) x=255; else if (x<0) x=0;x=x+0.49;
    #define CVT(x,y) CLIP(x);*y=(uint8_t)floor(x);

    CVT(rr,r);
    CVT(gg,g);
    CVT(bb,b);

    return 1;
}